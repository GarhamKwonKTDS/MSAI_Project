# nodes/case_narrowing.py

import logging
from typing import Dict, Any, List, Optional
from langchain_openai import AzureChatOpenAI
from models.state import ChatbotState, update_state_metadata
from services.azure_search import search_service

logger = logging.getLogger(__name__)

def case_narrowing_node(state: ChatbotState, config: Dict[str, Any], llm: AzureChatOpenAI) -> ChatbotState:
    """
    ì¼€ì´ìŠ¤ ì¢íˆê¸° ë…¸ë“œ - í™•ì •ëœ ì´ìŠˆ ë‚´ì—ì„œ êµ¬ì²´ì ì¸ ì¼€ì´ìŠ¤ ê²°ì •
    
    í”„ë¡œì„¸ìŠ¤:
    1. í˜„ì¬ ì´ìŠˆ íƒ€ì…ìœ¼ë¡œ í•„í„°ë§ëœ ì¼€ì´ìŠ¤ë“¤ ê²€ìƒ‰
    2. ìˆ˜ì§‘ëœ ì •ë³´ì™€ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„
    3. LLMìœ¼ë¡œ ì¼€ì´ìŠ¤ ê²°ì • ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
    4. ì¼€ì´ìŠ¤ í™•ì • ë˜ëŠ” ì¶”ê°€ ì§ˆë¬¸ í•„ìš” íŒë‹¨
    
    Args:
        state: í˜„ì¬ ì±—ë´‡ ìƒíƒœ
        config: ëŒ€í™” ì„¤ì • ì •ë³´
        llm: Azure OpenAI LLM ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        ChatbotState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
    """
    
    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    state = update_state_metadata(state, "case_narrowing")
    
    logger.info(f"ğŸ¯ Case Narrowing - Issue: {state['current_issue']}")
    logger.info(f"   Gathered Info: {len(state['gathered_info'])} items")
    logger.info(f"   Questions Asked: {state['question_count']}")
    
    try:
        # 1. í˜„ì¬ ì´ìŠˆ íƒ€ì…ìœ¼ë¡œ í•„í„°ë§ëœ ì¼€ì´ìŠ¤ë“¤ ê²€ìƒ‰
        filtered_cases = _search_cases_by_issue(state, config)
        
        if not filtered_cases:
            logger.warning("   âš ï¸ No cases found for current issue")
            state['needs_escalation'] = True
            state['escalation_reason'] = "no_cases_found"
            state['final_response'] = config['fallback_responses']['escalation']
            return state
        
        # 2. ìˆ˜ì§‘ëœ ì •ë³´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        conversation_context = _build_conversation_context(state)
        
        # 3. LLMìœ¼ë¡œ ì¼€ì´ìŠ¤ ê²°ì • ì‹œë„
        case_decision = _analyze_case_with_llm(
            state, 
            filtered_cases, 
            conversation_context, 
            config, 
            llm
        )
        
        # 4. ì¼€ì´ìŠ¤ ê²°ì • ê²°ê³¼ ì²˜ë¦¬
        if case_decision['case_determined']:
            # ì¼€ì´ìŠ¤ í™•ì •
            state['current_case'] = case_decision['case_id']
            state['solution_ready'] = True
            state['classification_confidence'] = case_decision['confidence']
            
            logger.info(f"   âœ… Case determined: {case_decision['case_id']} (confidence: {case_decision['confidence']:.2f})")
            
        elif case_decision['needs_question']:
            # ì¶”ê°€ ì§ˆë¬¸ í•„ìš”
            logger.info("   ğŸ“ Additional information needed")
            # Question Generatorê°€ ì²˜ë¦¬í•˜ë„ë¡ ìƒíƒœ ì„¤ì •
            state['solution_ready'] = False
            
        else:
            # ê²°ì • ë¶ˆê°€ - ì—ìŠ¤ì»¬ë ˆì´ì…˜
            logger.info("   âš ï¸ Cannot determine case - escalating")
            state['needs_escalation'] = True
            state['escalation_reason'] = "case_undetermined"
            state['final_response'] = config['fallback_responses']['escalation']
        
    except Exception as e:
        logger.error(f"   âŒ Case narrowing error: {e}")
        state['error_count'] += 1
        
        if state['error_count'] < 3:
            state['final_response'] = config['fallback_responses']['general_error']
        else:
            state['needs_escalation'] = True
            state['escalation_reason'] = "too_many_errors"
            state['final_response'] = config['fallback_responses']['escalation']
    
    return state

def _search_cases_by_issue(state: ChatbotState, config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    í˜„ì¬ ì´ìŠˆ íƒ€ì…ìœ¼ë¡œ í•„í„°ë§ëœ ì¼€ì´ìŠ¤ë“¤ ê²€ìƒ‰
    
    Args:
        state: í˜„ì¬ ì±—ë´‡ ìƒíƒœ
        config: ì„¤ì • ì •ë³´
        
    Returns:
        List[Dict]: í•„í„°ë§ëœ ì¼€ì´ìŠ¤ë“¤
    """
    
    if not state['current_issue']:
        return []
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ì™€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ê²°í•©í•œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
    search_query = state['user_message']
    
    # ìˆ˜ì§‘ëœ ë‹µë³€ë“¤ë„ ê²€ìƒ‰ ì¿¼ë¦¬ì— ì¶”ê°€
    if state['answers_received']:
        search_query += " " + " ".join(state['answers_received'][-2:])  # ìµœê·¼ 2ê°œ ë‹µë³€ë§Œ
    
    # ì´ìŠˆ íƒ€ì…ìœ¼ë¡œ í•„í„°ë§ëœ ê²€ìƒ‰
    filtered_cases = search_service.filter_cases_by_issue_type(
        query=search_query,
        issue_type=state['current_issue'],
        top_k=5
    )
    
    logger.info(f"   ğŸ” Found {len(filtered_cases)} cases for issue '{state['current_issue']}'")
    return filtered_cases

def _build_conversation_context(state: ChatbotState) -> str:
    """
    ëŒ€í™” ë§¥ë½ êµ¬ì„±
    
    Args:
        state: í˜„ì¬ ì±—ë´‡ ìƒíƒœ
        
    Returns:
        str: ëŒ€í™” ë§¥ë½ í…ìŠ¤íŠ¸
    """
    
    context_parts = []
    
    # ì´ˆê¸° ì‚¬ìš©ì ë©”ì‹œì§€
    context_parts.append(f"ì´ˆê¸° ë¬¸ì˜: {state['user_message']}")
    
    # ìˆ˜ì§‘ëœ ì •ë³´
    if state['gathered_info']:
        context_parts.append("ìˆ˜ì§‘ëœ ì •ë³´:")
        for key, info in state['gathered_info'].items():
            if isinstance(info, dict):
                context_parts.append(f"- {info.get('question', key)}: {info.get('answer', 'N/A')}")
            else:
                context_parts.append(f"- {key}: {info}")
    
    # ìµœê·¼ ëŒ€í™” ê¸°ë¡
    if state['conversation_history']:
        context_parts.append("ìµœê·¼ ëŒ€í™”:")
        for turn in state['conversation_history'][-3:]:  # ìµœê·¼ 3í„´ë§Œ
            context_parts.append(f"- ì‚¬ìš©ì: {turn.get('user', '')}")
            if turn.get('bot'):
                context_parts.append(f"- ë´‡: {turn.get('bot', '')[:100]}...")
    
    return "\n".join(context_parts)

def _analyze_case_with_llm(
    state: ChatbotState,
    cases: List[Dict[str, Any]], 
    conversation_context: str,
    config: Dict[str, Any], 
    llm: AzureChatOpenAI
) -> Dict[str, Any]:
    """
    LLMì„ ì‚¬ìš©í•œ ì¼€ì´ìŠ¤ ë¶„ì„ ë° ê²°ì •
    
    Args:
        state: í˜„ì¬ ì±—ë´‡ ìƒíƒœ
        cases: ê°€ëŠ¥í•œ ì¼€ì´ìŠ¤ë“¤
        conversation_context: ëŒ€í™” ë§¥ë½
        config: ì„¤ì • ì •ë³´
        llm: LLM ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        Dict: ì¼€ì´ìŠ¤ ê²°ì • ê²°ê³¼
    """
    
    # ì¼€ì´ìŠ¤ ì •ë³´ êµ¬ì„±
    case_descriptions = []
    for i, case in enumerate(cases, 1):
        case_info = f"""
ì¼€ì´ìŠ¤ {i}: {case.get('case_name', 'Unknown')} (ID: {case.get('case_type', case.get('id', ''))})
ì„¤ëª…: {case.get('description', '')}
ì¼ë°˜ì ì¸ ì¦ìƒ: {', '.join(case.get('symptoms', [])[:3])}
í™•ì¸ì´ í•„ìš”í•œ ì •ë³´: {', '.join(case.get('questions_to_ask', [])[:2])}
"""
        case_descriptions.append(case_info)
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_template = config['conversation_flow']['case_narrowing']['prompt_template']
    confidence_threshold = config['conversation_flow']['case_narrowing']['confidence_threshold']
    
    full_prompt = f"""
{prompt_template.format(
    issue=state['current_issue'],
    user_message=state['user_message'],
    conversation_context=conversation_context
)}

ê°€ëŠ¥í•œ ì¼€ì´ìŠ¤ë“¤:
{chr(10).join(case_descriptions)}

í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ê²°ì •í•˜ì„¸ìš”:

1. ì¼€ì´ìŠ¤ê°€ ì¶©ë¶„íˆ ëª…í™•í•˜ë‹¤ë©´ (ì‹ ë¢°ë„ {confidence_threshold} ì´ìƒ):
   ê²°ì •: CASE_DETERMINED
   ì¼€ì´ìŠ¤ID: [ê°€ì¥ ì í•©í•œ ì¼€ì´ìŠ¤ì˜ ID]
   ì‹ ë¢°ë„: [0.0-1.0]
   ì´ìœ : [ê²°ì • ê·¼ê±°]

2. ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•˜ë‹¤ë©´:
   ê²°ì •: NEED_MORE_INFO
   ì´ìœ : [ì–´ë–¤ ì •ë³´ê°€ ë” í•„ìš”í•œì§€]
   
3. ì¼€ì´ìŠ¤ë¥¼ ê²°ì •í•  ìˆ˜ ì—†ë‹¤ë©´:
   ê²°ì •: UNDETERMINED
   ì´ìœ : [ê²°ì •í•  ìˆ˜ ì—†ëŠ” ì´ìœ ]

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
ê²°ì •: [CASE_DETERMINED/NEED_MORE_INFO/UNDETERMINED]
ì¼€ì´ìŠ¤ID: [í•´ë‹¹í•˜ëŠ” ê²½ìš°]
ì‹ ë¢°ë„: [í•´ë‹¹í•˜ëŠ” ê²½ìš°, 0.0-1.0]
ì´ìœ : [ìƒì„¸í•œ ì„¤ëª…]
"""
    
    try:
        response = llm.invoke(full_prompt)
        result = response.content.strip()
        
        # ì‘ë‹µ íŒŒì‹±
        decision = _parse_case_decision(result, confidence_threshold)
        
        logger.info(f"   ğŸ¤– LLM Decision: {decision['decision']}")
        if decision.get('case_id'):
            logger.info(f"   ğŸ“‹ Selected Case: {decision['case_id']}")
            
        return decision
        
    except Exception as e:
        logger.error(f"LLM case analysis error: {e}")
        return {
            'case_determined': False,
            'needs_question': True,
            'decision': 'ERROR',
            'confidence': 0.0
        }

def _parse_case_decision(response: str, confidence_threshold: float) -> Dict[str, Any]:
    """
    LLM ì¼€ì´ìŠ¤ ê²°ì • ì‘ë‹µ íŒŒì‹±
    
    Args:
        response: LLM ì‘ë‹µ
        confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        
    Returns:
        Dict: íŒŒì‹±ëœ ê²°ì • ê²°ê³¼
    """
    
    lines = response.split('\n')
    decision = None
    case_id = None
    confidence = 0.0
    reason = ""
    
    for line in lines:
        line = line.strip()
        if line.startswith('ê²°ì •:'):
            decision = line.replace('ê²°ì •:', '').strip()
        elif line.startswith('ì¼€ì´ìŠ¤ID:'):
            case_id = line.replace('ì¼€ì´ìŠ¤ID:', '').strip()
        elif line.startswith('ì‹ ë¢°ë„:'):
            try:
                confidence_str = line.replace('ì‹ ë¢°ë„:', '').strip()
                confidence = float(confidence_str)
            except ValueError:
                confidence = 0.0
        elif line.startswith('ì´ìœ :'):
            reason = line.replace('ì´ìœ :', '').strip()
    
    # ê²°ì • ê²°ê³¼ êµ¬ì„±
    if decision == 'CASE_DETERMINED' and case_id and confidence >= confidence_threshold:
        return {
            'case_determined': True,
            'needs_question': False,
            'case_id': case_id,
            'confidence': confidence,
            'decision': decision,
            'reason': reason
        }
    elif decision == 'NEED_MORE_INFO':
        return {
            'case_determined': False,
            'needs_question': True,
            'decision': decision,
            'confidence': confidence,
            'reason': reason
        }
    else:
        return {
            'case_determined': False,
            'needs_question': False,
            'decision': decision or 'UNDETERMINED',
            'confidence': confidence,
            'reason': reason
        }

def get_next_action(state: ChatbotState) -> str:
    """
    Case Narrowing í›„ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
    LangGraph conditional_edgesì—ì„œ ì‚¬ìš©
    
    Args:
        state: í˜„ì¬ ì±—ë´‡ ìƒíƒœ
        
    Returns:
        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„
    """
    
    if state['needs_escalation']:
        return "END"
    elif state['solution_ready']:
        return "solution_delivery"
    else:
        return "question_generation"